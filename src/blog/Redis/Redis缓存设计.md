---
icon: file-lines
# 标题
title: 'Redis缓存设计'
# 设置作者
author: Ms.Zyh
# 设置写作时间
date: 2022-04-20
# 一个页面可以有多个分类
category:
  - Redis
# 一个页面可以有多个标签
tag:
  - 进阶
  - Redis
# 此页面会在文章列表置顶
sticky: false
# 此页面会出现在星标文章中
star: false
---

### 一，缓存穿透

**问题描述**：

​	key对应的数据并不存在，每次针对此key的请求从缓存获取不到，请求都会压到数据源，从而可能压垮数据源。比如用一个不存在的用户id获取用户信息，不论缓存还是数据库都没有，若黑客利用此漏洞进行攻击可能压垮数据库。

**解决方式**：

- 空值缓存：如果一个查询返回的数据为空，不管数据是否不存在，我们仍然把这个空结果（null）进行缓存，设置空结果的过期时间会很短，最长不超过五分钟。
- 加锁：根据key从缓存中获取到的value为空时，先锁上，再去查DB将数据加载到缓存，若其它线程获取锁失败，则等待一段时间后重试，从而避免了大量请求直接打到DB。单机可以使用synchronized或ReentrantLock加锁，分布式环境需要加分布式锁，如Redis分布式锁
- 采用布隆过滤器：对于恶意攻击，向服务器请求大量不存在的数据造成的缓存穿透，还可以用布隆过滤器先做一次过滤，对于不存在的数据布隆过滤器一般都能够过滤掉，不让请求再往后端发送。布隆过滤器判断某个值存在时，这个值可能不存在；但是当它说不存在时，那就肯定不存在。

​	布隆过滤器的空间效率非常好，它是一个二进制向量，每一位存放的是0或1，初始时默认为0，缓存空间占用很少，有点像redis的BitMap数据类型。

​	当一个元素加入集合时，根据元素的key，通过几个不一样的无偏 hash 函数（所谓无偏就是能够把元素的 hash 值算得比较均匀 ），得几个算得比较均匀整数索引值，然后对位数组长度进行取模运算得到几个位置，再把位数组的这几个位置都置为 1 就完成了添加操作。

<img src="http://img.zouyh.top/article-img/20240917135021213.png" alt="image-20230310100955295" style="zoom:80%;" />

​	向布隆过滤器询问 key 是否存在时，跟 add 一样，也会把 hash 的几个位置都算出来，看看位数组中这几个位置是否都为 1，只要有一个位为 0，那么说明布隆过滤器中这个key 不存在。如果都是 1，这并不能说明这个 key 就一定存在，只是极有可能存在，因为这些位被置为 1 可能是因为其它的 key 存在所致。如果这个位数组长度比较大，存在概率就会很大，如果这个位数组长度比较小，存在概率就会降低。

可以用redisson实现布隆过滤器，引入依赖：

```xml
<dependency>
   <groupId>org.redisson</groupId>
   <artifactId>redisson</artifactId>
   <version>3.6.5</version>
</dependency>
```

示例伪代码：

```java
public class RedissonBloomFilter {
    public static void main(String[] args) {
        Config config = new Config();
        config.useSingleServer().setAddress("redis://localhost:6379");
        //构造Redisson
        RedissonClient redisson = Redisson.create(config);
        RBloomFilter<String> bloomFilter = redisson.getBloomFilter("nameList");
        //初始化布隆过滤器：预计元素为100000000L,误差率为3%,根据这两个参数会计算出底层的bit数组大小
        bloomFilter.tryInit(100000000L,0.03);
        bloomFilter.add("zyh");//将zhuge插入到布隆过滤器中
        //判断下面号码是否在布隆过滤器中
        System.out.println(bloomFilter.contains("zyh01"));//false
        System.out.println(bloomFilter.contains("zyh02"));//false
        System.out.println(bloomFilter.contains("zyh"));//true
    }
}
```

使用布隆过滤器需要把所有数据提前放入布隆过滤器，并且在增加数据时也要往布隆过滤器里放：

```java
//把所有数据存入布隆过滤器
for (String key: keys) {
    bloomFilter.put(key);
}
```

查值的时候可以先从 布隆过滤器这一级缓存判断下key是否存在    

```java
String get(String key) {
    // 从布隆过滤器这一级缓存判断下key是否存在
    Boolean exist = bloomFilter.contains(key);
    if(!exist){
        return "";
    }
	String cacheValue = cache.get(key);// 从缓存中获取数据
	if (StringUtils.isBlank(cacheValue)) {// 缓存为空
		String storageValue = storage.get(key);// 从存储中获取
		cache.set(key, storageValue);
		if (storageValue == null) { // 如果存储数据为空， 需要设置一个过期时间(300秒)
			cache.expire(key, 60 * 5);
		}
		return storageValue;
	} else {
		// 缓存非空
		return cacheValue;
	}
}
```

> 注意：布隆过滤器不能删除数据，如果要删除得重新初始化数据。

### 二，缓存击穿

**问题描述：**

说缓存击穿之前，我们先来了解一个概念——热点key，某个访问非常频繁，访问量非常大的一个缓存key，我们叫做热点key。

缓存击穿是指某个热点key在失效的瞬间（一般是缓存时间到期），持续的大并发请求穿破缓存，直接打到数据库，就像在一个屏障上凿开了一个洞，造成数据库压力瞬间增大，这就是缓存击穿。

**解决方式：**

- 设置热点key永不过期
- 加锁，根据热点key从缓存中获取到的value为空时，先锁上，再去查DB将数据加载到缓存，若其它线程获取锁失败，则等待一段时间后重试，从而避免了大量请求直接打到DB。单机可以使用synchronized或ReentrantLock，分布式需要加分布式锁，如Redis分布式锁。为了不阻塞对其他key的请求，此处可以用热点key来加锁。

### 三，缓存雪崩

**问题描述：**

​	非常多的key对应的数据本来是存在，但在某一时刻这些key都过期，此时若有大量并发请求过来，发现缓存过期了，一般都会从后端DB加载数据并回设到缓存，但是由于请求太多，并发太高，可能会瞬间把后端DB压垮。缓存雪崩与缓存击穿的区别在于这里针对很多key缓存，前者则是某一个key。

**解决方式：**

- 保证缓存层服务高可用性，比如使用Redis Sentinel或Redis Cluster。 依赖隔离组件为后端限流熔断并降级减少请求。
- 热点缓存重构：可以利用互斥锁来解决，此方法只允许一个线程重建缓存， 其他线程等待重建缓存的线程执行完， 重新从缓存获取数据即可

```java
String get(String key) {
    String value = redis.get(key); // 从Redis中获取数据
    if (value == null) {// 如果value为空， 则开始重构缓存
        String mutexKey = "mutext:key:" + key;// 只允许一个线程重建缓存， 使用nx， 并设置过期时间ex
        if (redis.set(mutexKey, "1", "ex 180", "nx")) {
            value = db.get(key); // 从数据源获取数据
            redis.setex(key, timeout, value); // 回写Redis， 并设置过期时间
            redis.delete(mutexKey);// 删除key_mutex
        }else {
            Thread.sleep(50);// 其他线程休息50毫秒后重试
            get(key);
        }
    }
    return value;
}
```

- 将缓存失效时间分散开：比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。

```java
String get(String key) {
    String cacheValue = cache.get(key);// 从缓存中获取数据
    if (StringUtils.isBlank(cacheValue)) {// 缓存为空
        String storageValue = storage.get(key);// 从存储中获取
        cache.set(key, storageValue);
        int expireTime = new Random().nextInt(300)  + 300;//设置一个过期时间(300到600之间的一个随机数)
        if (storageValue == null) {
            cache.expire(key, expireTime);
        }
        return storageValue;
    } else {
        return cacheValue;
    }
}
```

### 四，缓存与数据库双写不一致

数据库和缓存（比如：redis）双写数据一致性问题，是一个跟开发语言无关的公共问题。尤其在高并发的场景下，这个问题变得更加严重。

通常情况下，我们使用缓存的主要目的是为了提升查询的性能。大多数情况下，我们是这样使用缓存的：

<img src="http://img.zouyh.top/article-img/20240917135020212.png" alt="image-20230309171837951" style="zoom: 50%;" />

这是缓存非常常见的用法。一眼看上去，好像没有啥问题。但你忽略了一个非常重要的细节：如果数据库中的某条数据，放入缓存之后，又立马被更新了，那么该如何更新缓存呢？

从理论上来说，给缓存设置过期时间，是保证最终一致性的解决方案，缓存一旦过期，再次查询的时候，就会查询数据库中的最新数据，然后更新到缓存中。不考虑缓存过期的情况，更新缓存有以下4种方式：

#### 4.1 先写缓存，再写数据库

先写缓存，再写数据库的情况，这套方案，大家是普遍反对的，因为它的问题最严重。

​	案例1：某一个用户的每一次写操作，如果刚写完缓存，突然网络出现了异常，导致写数据库失败了。其结果是缓存更新成了最新数据，但数据库没有，这样缓存中的数据不就变成脏数据了？如果此时该用户的查询请求，正好读取到该数据，就会出现问题，因为该数据在数据库中根本不存在，这个问题非常严重。

​	案例2：线程A先更新了缓存，线程A由于等等原因还未更新数据库，这时候线程B又更新了缓存，然后线程B更新了数据库，线程A接着更新了数据库，其结果是缓存中存储的是线程B写入的数据，数据库保存的是线程A，这样缓存中的数据不就变成脏数据了？如果此时该用户的查询请求，不考虑缓存过期的情况，读取的缓存值一直都不是数据库的值。

综上所诉，先写缓存再写数据库这个方案不能使用。

#### 4.2 先写数据库，再写缓存

先写数据库，再写缓存的情况，这套方案，怎么说呢还是有问题。

案例：线程A先更新数据库，线程A由于等等原因还未更新了缓存，这时候线程B又更新了数据库，然后线程B更新了缓存，线程A接着更新了缓存，其结果是缓存中存储的是线程A写入的数据，数据库保存的是线程B，这样缓存中的数据不就变成脏数据了？如果此时该用户的查询请求，不考虑缓存过期的情况，读取的缓存值一直都不是数据库的值。这也是非常浪费资源的，线程B更新了缓存可能还没有使用，就被线程A更新缓存直接覆盖了。

#### 4.3 先删除缓存，再写数据库

先写数据库，再写缓存的情况，这套方案，怎么说呢比上面的两个方案较好，最起码删除缓存，不浪费redis空间hhh，但是也是存在些问题的，他的问题和先写缓存，再写数据库基本上一样。

案例：线程A先删除了缓存，线程A由于等等原因还未更新数据库，这时候线程B查询，发现缓存没值，就去查询数据库的数据然后更新缓存，线程A接着更新了数据库，数据库保存的是线程A，缓存中保存的是线程B在线程A更新数据之前的旧数据，这样缓存中的数据不就变成脏数据了？如果此时该用户的查询请求，不考虑缓存过期的情况，读取的缓存值一直都不是数据库的值。

解决方式：延时双删策略

​	在上面的业务场景中，线程A把缓存删了之后，线程B读到旧值并写入缓存当中，造成缓存中保存的是旧值。但是如果线程A删除两次我写之前删除，写之后再删一次，为了保证'写之后再删一次'能大概率删除B读旧值缓存，设置一个延迟时间，具体时间具体分析，不能太长，太长线程A处理的时间太久了，不能太短，太短线程B读到旧值还没来得及写入缓存。

#### 4.3 先写数据库，再删除缓存

先删缓存，再更新数据库和先更新数据库，再删缓存一直就是争议最大的，不过这种方式是使用最多，但是这种方式不是不存在并发问题。

案例：假设缓存过期时间到了，自动失效，线程A读数据库的值，线程A由于等等原因还未将值写入缓存中，这时候线程B更新了数据库并且清空了缓存，线程A接着将值写入缓存中，数据库保存的是线程B，缓存中保存的是线程A在线程B更新数据之前的旧数据，这样缓存中的数据不就变成脏数据了。

为什么推荐使用先写数据库，再删除缓存，因为上述案例发生的机率较小，需要同时满足以下条件才可以：

- 缓存刚好自动失效。
- 线程A查询数据库旧值+删除缓存的耗时  大于 线程B更新数据库值+删除缓存的耗时

​	先写数据库，再删缓存的方案，跟缓存双删的方案一样，有一个共同的风险点，即如果缓存删除失败了，也会导致缓存和数据库的数据不一致。那么，删除缓存失败怎么办呢？需要加重试机制。可以通过异步重试方式一直尝试删除数据，比如可以用阿里开源的canal通过监听数据库的binlog日志及时的去修改缓存，但是引入了新的中间件，增加了系统的复杂度。或者使用MQ消息队列，也引入了新的中间件，增加了系统的复杂度，或则直接在程序中另起一个线程，每隔一段时间去重试等等。

#### 4.5 总结

​	以上的四种方案都会或多或少的存在一些数据不一致的时间段，如果不能容忍，必须要保证缓存数据一致，可以通过加读写锁保证并发读写或写写的时候按顺序排好队，读读的时候相当于无锁。通过加锁的方式保证缓存数据的强一致性情况只是适用于读多写少的情况，如果写多读多的情况又不能容忍缓存数据不一致，那 就没必要加缓存了，可以直接操作数据库。放入缓存的数据应该是对实时性、一致性要求不是很高的数据。切记不要为了用缓存，同时又要保证绝对的一致性做大量的过度设计和控制，增加系统复杂性！

### 五，开发规范与性能优化

#### 5.1 键值设计

#####  5.1.1 key名设计：

- 可读性和可管理性，以业务名(或数据库名)为前缀(防止key冲突)，用冒号分隔，比如业务名:表名:id，`trade:order:1              `
- 简洁性，保证语义的前提下，控制key的长度，当key较多时，内存占用也不容忽视，例如：`user:{uid}:friends:messages:{mid} 简化为 u:{uid}:fr:m:{mid}              `
- 不要包含特殊字符：不要包含空格、换行、单双引号以及其他转义字符
- 控制key的生命周期，redis不是垃圾桶，建议使用expire设置过期时间(条件允许可以打散过期时间，防止集中过期)

##### 5.1.2 value设计：

①，拒绝bigkey(防止网卡流量、慢查询)：

在Redis中，一个字符串最大512MB，一个二级数据结构（例如hash、list、set、zset）可以存储大约40亿个(2^32-1)个元素，但实际中如果下面两种情况，我就会认为它是bigkey。

- 字符串类型：它的big体现在单个value值很大，一般认为超过10KB就是bigkey。
- 非字符串类型：哈希、列表、集合、有序集合，它们的big体现在元素个数太多，一般不要超过5000。

②，bigkey的危害：

- 导致redis阻塞
- 网络拥塞：bigkey也就意味着每次获取要产生的网络流量较大，假设一个bigkey为1MB，客户端每秒访问量为1000，那么每秒产生1000MB的流量，对于普通的千兆网卡(按照字节算是128MB/s)的服务器来说简直是灭顶之灾，而且一般服务器会采用单机多实例的方式来部署，也就是说一个bigkey可能会对其他实例也造成影响，其后果不堪设想。
- 过期删除：有个bigkey，它安分守己（只执行简单的命令，例如hget、lpop、zscore等），但它设置了过期时间，当它过期后，会被删除如果没有使用Redis 4.0的过期异步删除`lazyfree-lazy-expire yes`，就会存在阻塞Redis的可能性。

③，如何优化bigkey：

- 存值：拆，可以将数据分段存储，比如一个大的key，假设存了1百万的用户数据，可以拆分成200个key，每个key下面存放5000个用户数据。
- 取值：如果bigkey不可避免，也要思考一下要不要每次把所有元素都取出来(例如有时候仅仅需要hmget，而不是hgetall)，删除也是一样，尽量使用优雅的方式来处理。
- 删除：非字符串的bigkey，不要使用del删除，使用hscan、sscan、zscan方式渐进式删除，同时要注意防止bigkey过期时间自动删除问题，例如一个200万的zset设置1小时过期，会触发del操作，造成阻塞。
- 选择适合的数据类型：例如：实体类型(要合理控制和使用数据结构，但也要注意节省内存和性能之间的平衡)

#### 5.2 命令使用

1.  O(N)命令关注N的数量：例如hgetall、lrange、smembers、zrange、sinter等并非不能使用，但是需要明确N的值。有遍历的需求可以使用hscan、sscan、zscan代替。
2. 禁用命令：禁止线上使用keys、flushall、flushdb等，通过redis的rename机制禁掉命令，或者使用scan的方式渐进式处理。
3. 合理使用select：redis的多数据库较弱，使用数字进行区分，很多客户端支持较差，同时多业务用多数据库实际还是单线程处理，会有干扰。
4. 使用批量操作提高效率：原生命令：例如mget、mset。 非原生命令：可以使用pipeline提高效率。 但要注意控制一次批量操作的元素个数(例如500以内，实际也和元素字节数有关)。注意两者不同：1. 原生命令是原子操作，pipeline是非原子操作。 2. pipeline可以打包不同的命令，原生命令做不到 3. pipeline需要客户端和服务端同时支持。              
5. Redis事务功能较弱，不建议过多使用，可以用lua替代

#### 5.3 客户端使用

连接池参数含义：

| 序号 | 参数名             | 含义                                                         | 默认值           | 使用建议                                          |
| ---- | ------------------ | ------------------------------------------------------------ | ---------------- | ------------------------------------------------- |
| 1    | maxTotal           | 资源池中最大连接数                                           | 8                | 设置建议见下面                                    |
| 2    | maxIdle            | 资源池允许最大空闲的连接数                                   | 8                | 设置建议见下面                                    |
| 3    | minIdle            | 资源池确保最少空闲的连接数                                   | 0                | 设置建议见下面                                    |
| 4    | blockWhenExhausted | 当资源池用尽后，调用者是否要等待。只有当为true时，下面的maxWaitMillis才会生效 | true             | 建议使用默认值                                    |
| 5    | maxWaitMillis      | 当资源池连接用尽后，调用者的最大等待时间(单位为毫秒)         | -1：表示永不超时 | 不建议使用默认值                                  |
| 6    | testOnBorrow       | 向资源池借用连接时是否做连接有效性检测(ping)，无效连接会被移除 | false            | 业务量很大时候建议设置为false(多一次ping的开销)。 |
| 7    | testOnReturn       | 向资源池归还连接时是否做连接有效性检测(ping)，无效连接会被移除 | false            | 业务量很大时候建议设置为false(多一次ping的开销)。 |
| 8    | jmxEnabled         | 是否开启jmx监控，可用于监控                                  | true             | 建议开启，但应用本身也要开启                      |

优化建议：

1，maxTotal：最大连接数，早期的版本叫maxActive，实际上这个是一个很难回答的问题，考虑的因素比较多：

- 业务希望Redis并发量
- 客户端执行命令时间
- Redis资源：例如 nodes(例如应用个数) maxTotal 是不能超过redis的最大连接数maxclients。
- 资源开销：例如虽然希望控制空闲连接(连接池此刻可马上使用的连接)，但是不希望因为连接池的频繁释放创建连接造成不必靠开销。

​	假设:一次命令时间的平均耗时约为1ms，一个连接的QPS(每秒请求数)大约是1000，业务期望的QPS是50000，那么理论上需要的资源池大小是50000 / 1000 = 50个。但事实上这是个理论值，还要考虑到要比理论值预留一些资源，通常来讲maxTotal可以比理论值大一些。但这个值不是越大越好，一方面连接太多占用客户端和服务端资源，另一方面对于Redis这种高QPS的服务器，一个大命令的阻塞即使设置再大资源池仍然会无济于事。

2，maxIdle和minIdle

maxIdle实际上才是业务需要的最大连接数，maxTotal是为了给出余量，所以maxIdle不要设置过小，否则会有new Jedis(新连接)开销。

连接池的最佳性能是`maxTotal = maxIdle`，这样就避免连接池伸缩带来的性能干扰。但是如果并发量不大或者maxTotal设置过高，会导致不必要的连接资源浪费。一般推荐maxIdle可以设置为按上面的业务期望QPS计算出来的理论连接数，maxTotal可以再放大一倍。

minIdle（最小空闲连接数），与其说是最小空闲连接数，不如说是"至少需要保持的空闲连接数，在使用连接的过程中，如果连接数超过了minIdle，那么继续建立连接，如果超过了maxIdle，当超过的连接执行完业务后会慢慢被移出连接池释放掉。如果系统启动完马上就会有很多的请求过来，那么可以给redis连接池做预热，比如快速的创建一些redis连接，执行简单命令，类似ping()，快速的将连接池里的空闲连接提升到minIdle的数量。连接池预热示例代码：

```java
List<Jedis> minIdleJedisList = new ArrayList<Jedis>(jedisPoolConfig.getMinIdle());
for (int i = 0; i < jedisPoolConfig.getMinIdle(); i++) {
    Jedis jedis = null;
    try {
        jedis = pool.getResource();
        minIdleJedisList.add(jedis);
        jedis.ping();
    } catch (Exception e) {
        logger.error(e.getMessage(), e);
    } finally {
        //注意，这里不能马上close将连接还回连接池，否则最后连接池里只会建立1个连接。。
        //jedis.close();
    }
}
//统一将预热的连接还回连接池
for (int i = 0; i < jedisPoolConfig.getMinIdle(); i++) {
    Jedis jedis = null;
    try {
        jedis = minIdleJedisList.get(i);
        //将连接归还回连接池
        jedis.close();
    } catch (Exception e) {
        logger.error(e.getMessage(), e);
    } finally {
    }
}
```

### 六，Redis对于过期键有三种清除策略

　　我们set key的时候，都可以给一个expire time，就是过期时间，指定这个key比如说只能存活1个小时，我们自己可以指定缓存到期就失效。如果假设你设置一个一批key只能存活1个小时，那么接下来1小时后，redis是怎么对这批key进行删除的？

- 惰性删除/被动删除：当读/写一个已经过期的key时，会触发惰性删除策略，直接删除掉这个过期key。
- 定期删除/主动删除：当没有读/写一个已经过期的key时，惰性删除策略无法保证冷数据被及时删掉，所以Redis会定期(默认每100ms)主动淘汰一批已过期的key，这里的一批只是部分过期key，所以可能会出现部分key已经过期但还没有被清理掉的情况，导致内存并没有被释放
- 当前已用内存超过maxmemory限定时，触发定期删除/主动删除

定期删除/主动删除在Redis 4.0 之前一共实现了 6 种内存淘汰策略，在 4.0 之后，又增加了 2 种策略，总共8种：

- 第一大类，针对设置了过期时间的key做处理：
  - `volatile-ttl`：在筛选时，会针对设置了过期时间的键值对，根据过期时间的先后进行删除，越早过期的越先被删除。
  - `volatile-random`：就像它的名称一样，在设置了过期时间的键值对中，进行随机删除。
  - `volatile-lru`：会使用 LRU 算法筛选设置了过期时间的键值对删除。
  - `volatile-lfu`：会使用 LFU 算法筛选设置了过期时间的键值对删除。
- 第二大类，针对所有的key做处理：
  - allkeys-random`：从所有键值对中随机选择并删除数据。
  - `allkeys-lru`：使用 LRU 算法在所有数据中进行筛选删除。
  - `allkeys-lfu`：使用 LFU 算法在所有数据中进行筛选删除。
- 第三大类，不处理：
  - noeviction`：不会剔除任何数据，拒绝所有写入操作并返回客户端错误信息"(error) OOM command not allowed when used memory"，此时Redis只响应读操作。

LRU 算法和LFU 算法：

- LRU 算法（Least Recently Used，最近最少使用）:淘汰很久没被访问过的数据，以**最近一次访问时间**作为参考。
- LFU 算法（Least Frequently Used，最不经常使用）：淘汰最近一段时间被访问次数最少的数据，以**次数**作为参考。

​	根据自身业务类型，配置好内存淘汰策略`maxmemory-policy`，默认是`noeviction`，推荐使用`volatile-lru`。如果不设置配置好内存淘汰策略，当 Redis 内存超出物理内存限制时，内存的数据会开始和磁盘产生频繁的交换 (swap)，会让 Redis 的性能急剧下降。当Redis运行在主从模式时，只有主结点才会执行过期删除策略，然后把删除操作”del key”同步到从结点删除数据。
